{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "izPT_K8sRUFe"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# For FIM\n",
    "import nngeometry\n",
    "from nngeometry import metrics\n",
    "from nngeometry.object.pspace import PMatDiag, PMatKFAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nngeometry.object import FMatDense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LoFTPkk_HMu",
    "outputId": "af3f2040-86da-4f4f-df0a-711afa9f3a94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_chkpt = False # Load from checkpoint in case of resuming training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102,
     "referenced_widgets": [
      "ebe265266f174d1cbee860e8ba4681d6",
      "5a57cf595789487991d2160c2c756e16",
      "42169e65d8b348e1b7571bd857d35121",
      "7d8c521b1e93440fa382f3205688df4c",
      "91e0cb15346342ef803ab724927a5045",
      "fb92c28c2ebe4b63ab23b1aa36fe0ff3",
      "2d4be4ffe46e422abda47318c8e6ebc0",
      "73044d7fc152463488f32f6c0cf4e687",
      "791e02267eb84006a020029d40d3f037",
      "f858fcc0d16f459087577041d8af7a81",
      "fcb12b772f9840b4b783ab83d65fc476"
     ]
    },
    "id": "jtFbPo2LRg0e",
    "outputId": "f34d323b-7912-48dd-881a-a6c600730a81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                transforms.RandomHorizontalFlip(),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "transform_blur = transforms.Compose([\n",
    "                                     transforms.Resize((8,8)),\n",
    "                                     transforms.Resize((32,32),interpolation=InterpolationMode.BILINEAR),\n",
    "                                     transforms.RandomCrop(32, padding=4),\n",
    "                                     transforms.RandomHorizontalFlip(),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "# CIFAR 10 Dataset\n",
    "train_dataset_clean = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform,\n",
    "                                             download=True)\n",
    "\n",
    "train_dataset_blur = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                             train=True, \n",
    "                                             transform=transform_blur,\n",
    "                                             download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data/',\n",
    "                                            train=False, \n",
    "                                            transform=transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "HonLDq8pARc3"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_loader_clean = torch.utils.data.DataLoader(dataset=train_dataset_clean,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "train_loader_blur = torch.utils.data.DataLoader(dataset=train_dataset_blur,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x3 convolution\n",
    "def conv3x3(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
    "                     stride=stride, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 16\n",
    "        self.conv = conv3x3(3, 16)\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
    "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            downsample = nn.Sequential(\n",
    "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels))\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# ResNet 18\n",
    "net = ResNet(ResidualBlock, [2, 2, 2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "C_K2L2tFjbqF"
   },
   "outputs": [],
   "source": [
    "# class AllCNNNet(nn.Module):\n",
    "#   def __init__(self):\n",
    "#     super().__init__()\n",
    "#     self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "#     self.pool = nn.MaxPool2d(2, 2)\n",
    "#     self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "#     self.fc1 = nn.Linear(16*5*5, 120)\n",
    "#     self.fc2 = nn.Linear(120, 84)\n",
    "#     self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     x = self.pool(F.relu(self.conv1(x)))\n",
    "#     x = self.pool(F.relu(self.conv2(x)))\n",
    "#     x = torch.flatten(x, 1)\n",
    "#     x = F.relu(self.fc1(x))\n",
    "#     x = F.relu(self.fc2(x))\n",
    "#     x = self.fc3(x)\n",
    "#     return x\n",
    "\n",
    "# net = AllCNNNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "EuN4qPtdLnc2"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "num_epochs_blur = 0\n",
    "num_epochs_clean = 220\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "We6ex2sWU_id"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001, momentum=0.9, nesterov=True)\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exHtl5Wh5lOA",
    "outputId": "055b7562-3dbf-4978-fb1e-139183359ba3"
   },
   "outputs": [],
   "source": [
    "# from torchsummary import summary\n",
    "\n",
    "# summary(net, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "AcryIUcMXipz"
   },
   "outputs": [],
   "source": [
    "# For updating learning rate\n",
    "def update_lr(optimizer, lr):    \n",
    "#     print (\"Updating LR\")\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAuM0lEQVR4nO3dd3RVVb7A8e8vnYQUUglJSCiRDgKhYwNUxILDqKOOim0cy4w6vik689bMe1OdYp2Zp4Oigjr2AiIjIjZ6CJ2EkpAE0nsPqXe/P+4hJhAgSJKbe+/vs9ZduWeffe79nXXgl5199tlbjDEopZRyLR6ODkAppVT30+SulFIuSJO7Ukq5IE3uSinlgjS5K6WUC/JydAAA4eHhJiEhwdFhKKWUU9m+fXupMSais319IrknJCSQkpLi6DCUUsqpiMiRU+3TbhmllHJBmtyVUsoFaXJXSikXpMldKaVckCZ3pZRyQZrclVLKBWlyV0opF9QnxrkrpZQ7aGm18cqmbI41teLj5YGPlwczhoUxcmBQt3+XJnellOol/9lXyO8/3t+h7A/fGavJXSmlnNmrW44QF9qPzx65iJZWQ1OLDT9vzx75Lu1zV0qpXnCgsJrkrHJumRaPr5cnAb5eDAjwoZ+PJnellHJar205go+XBzckxfXK92lyV0qpHlbT0MwHO/K4evwgBgT49Mp3anJXSqluVlLTyJ9W72dfXhUAH+zMo66pldtmxPdaDHpDVSmlutnTnx3i9a1H+dfXmcwbFUlGcS3jY4OZEBfSazFocldKqW5UWNXAOym5LJoYw5DwAF7ckEXVsWb+et34Xo1Dk7tSSnWjf319mFZj+Mml5xEX6s/tsxJIzirnkhGRvRqHJnellOomJTWN/HvrUb4zMYa4UH8AAv28mTsqqtdj0RuqSinVTV7ckElzq437Lx7m6FA0uSulVHeoqGvitc1HuGr8IIZG9Hd0OF1L7iISIiLvisgBEdkvIjNEJFRE1opIuvVzgFVXRORZEckQkT0iMqlnT0EppRwrp7ye77+4lWPNrTxwyXBHhwN0veX+DPCJMWYkMAHYDzwKrDPGJALrrG2AK4BE63UP8Fy3RqyUUr2g1WZoabWdsd769BKu/scGcirqeXFxEiMGBvZCdGd2xuQuIsHAhcBSAGNMkzGmElgILLOqLQOutd4vBJYbuy1AiIhEd3PcSinVo+57bTuXP/015XVNne4vr2vitx+lsfilZKIC/fjoR7OZM7L3b5yeSldGywwBSoCXRWQCsB14CIgyxhRYdQqB42cVA+S0Oz7XKitoV4aI3IO9Zc/gwYO/bfxKKdXt1qeX8GlaEQD3vrqdV++eiq+XfYKv+qYWlq7P4l9fZ1Lf1ML3pgzmv68cRYBv3xp82JVuGS9gEvCcMWYiUMc3XTAAGGMMYM7mi40xS4wxScaYpIiIiLM5VCmleozNZnj8PweIHdCPJ66fQHJ2OY+9t5dWm+HtbTlc/NcveWLtIWYOC+PTn1zInxaN63OJHbrWcs8Fco0xW63td7En9yIRiTbGFFjdLsXW/jyg/bRnsVaZUkr1eSt355OaX83T3zufayfGkFd5jCfXHmLT4TIKqxs4Py6E526ZxOT4UEeHelpnbLkbYwqBHBEZYRXNBdKAlcBiq2wxsMJ6vxK4zRo1Mx2oatd9o5RSfVZjSyt/XXOQMYOCuGbCIAB+PGc4N02Nw8/bg2dvmsgH98/s84kduv6E6o+B10XEB8gE7sD+i+FtEbkLOALcYNVdDSwAMoB6q65SSvV5r2zMJq/yGH+5bjweHgKAiPCnRb07L0x36FJyN8bsApI62TW3k7oGeODcwlJKqd718sYsHv/kAHNHRjJreLijwzlnfe8ugFJK9TB7G9TeKm+1GX63Ko1XNmVz2egonrlxooOj6x6a3JVSbqWhuZWr/76BrNI6gvt54+3pQWF1A3fOGsKvrhyFp9Ud4+w0uSul3MrLG7NJL67llumDsRmoOtbMRYkR3DCld9Y27S2a3JVSLmV9egljBgUT2slapSU1jfzziwzmjYrk99eOc0B0vUeTu1LKZaTmV3Hr0mQCfb249+Jh3DlrCP18PNv2P7n2EA3NrfxywSgHRtk7NLkrpVzG5sNlAEyMH8Bf1xzk1c1HuHVGPNdOjKGmoZm3th1l8cyEPjElb0/T5K6UchlbMstJCPNn+Z1T2ZpZxpNrD/HXNQf526cHCennTaCfNw/NTXR0mL1Ck7tSyiXYbIZt2eXMHzMQgGlDw3jrhzM4WlbPh7vy+GRfIXfOHkKI/8l98a5Ik7tSyiXsL6ym6lgz04Z2nBpgcJg/D85N5EE3abEfp8vsKaVcwtbMcsDeYlea3JVSLmJrVhlxof2ICenn6FD6BE3uSimnZ7MZkrPKmTZEW+3HaXJXSvVJ1Q3N/PKDvcz+8+fsyqk8bd304loq6puZNqTvT8XbWzS5K6X6nDWphcx74iveTD5KQ3MrN7+whQ3ppaesvyXTPr59uva3t9HkrpTqU55dl84PX91OaIAPHz4wi9UPXsDgUH/ufGUb/9nb+bo/W7PKiAnpR1yofy9H23dpcldK9RmbMkp56rNDXHv+ID768WzGx4YQGeTHW/fMYFxsMPf/ewePvb+HirqmtmOMOd7frl0y7ek4d6VUn1BS08hDb+1iaHgAf1w0Dm/Pb9qewf7evHbXNJ5ce5CXNmbzyb5C7r1oGJXHmtmeXUFpbdNJ49vdnSZ3pZTD2WyGR97eRfWxZl69ayr+Pienpn4+nvzqytF8d3Isv/4wlT/95wBeHsKYQUHcOWsIC8ZFOyDyvkuTu1LKoVptht9/nMb69FL++J1xjBwYdNr6IwcG8dYPp5NZWkdMSD/8vD1PW99daXJXSjlMeV0TD76xkw0Zpdw+M4GbpnZtwQwRYZgbzOx4LjS5K6UcYn9BNXcvS6GktpG/fHe8y62E5Gia3JVS3W5TRinNNsMFw8Px6GRN0lab4cE3dtLcauOdH85gQlxI7wfp4rqU3EUkG6gBWoEWY0ySiIQCbwEJQDZwgzGmQkQEeAZYANQDtxtjdnR/6Eqpvqil1cY9r26ntrGFIeEB3Do9nhumxNHf95t0s2pPPunFtfz9poma2HvI2Yxzv8QYc74xJsnafhRYZ4xJBNZZ2wBXAInW6x7gue4KVinV9+0vqKG2sYWbpsYR4u/Nb1elcf3zm6lvagHsyf+Zz9IZOTCQK3WES485l4eYFgLLrPfLgGvblS83dluAEBHRK6iUm9iaZZ8K4MG5iXxw/yyW3DqZg4XV/OydPRhjWLErn8zSOh6ed16nXTaqe3Q1uRvgUxHZLiL3WGVRxpjjzwIXAlHW+xggp92xuVZZByJyj4ikiEhKSUnJtwhdKeVIDc2t3LhkM5+lFXUo35ZdTlxoP6KD7VPvXjZmIL+YP5KP9xbwzLp0nlmXzphBQVw+Jqqzj1XdpKs3VGcbY/JEJBJYKyIH2u80xhgRMWfzxcaYJcASgKSkpLM6VinleCt357MlsxwvDw/mjbYnamMM27IruGREZIe691w4lLSCap7+LB2ApYuTsN+eUz2lS8ndGJNn/SwWkQ+AqUCRiEQbYwqsbpdiq3oe0H5MU6xVppRyEcYYXt6YDcDmzDLKahsJ6+/L4ZJayuuaTprnRUT483fHk1Nej6+XJ3NGRnbyqao7nbFbRkQCRCTw+HvgMmAfsBJYbFVbDKyw3q8EbhO76UBVu+4bpZQL2JpVzv6CahbPiKfVZliTWtRWDjClk0m8/Lw9effembx611RttfeCrvS5RwEbRGQ3kAx8bIz5BHgcuFRE0oF51jbAaiATyABeAO7v9qiVUr3KmI49py9tyGKAvzePLRjFkPAAVltT8W7LKici0JeEsM6n3vXwELw8dTLa3nDGbhljTCYwoZPyMmBuJ+UGeKBbolNKOVxWaR3XP7+JRZNi+ellIyiqbmDt/iLuu2gYft6eXDkumv/7MoOy2ka2ZpUzNSFUW+Z9gD6hqpQ6reWbsymra2LJ15lsOlzKkPD+eIpw64x4ABaMi+YfX2SwdEMWBVUNTNV51fsE/ftIKXVK9U0tvLs9l6vHD2LJrZPJrTjGR7vzuWJcdNtQx1HRgQwND+DFDVkAmtz7CG25K6VO6aPd+dQ0tHDrjHimJIQyPjaE5786zO0zE9rqiAhXjo/m759nEOTnxYioQMcFrNpoy10p1SljDK9uOcKIqECS4gcAMDDYj/+5ZgwJ4QEd6h5fKGNKQqg+ddpHaHJXSnVqd24V+/KquWVG/BlvkI4cGMj3pw3mlunxvRSdOhPtllFKderVzUcI8PHkOxNPmj3kJCLCH74zrheiUl2lLXel3Fh5XROvbTlCRV1Th/K0/GpW7cln0aTYDlP1KuehV00pN/aL9/awNq2IP67ezy3T47l0dBSvbMrm4z0FBPl5ccesBEeHqL4lTe5KObnimgY8RAjv73vKOss2ZfP5gWKevXEiwf7eAKxJLWRtWhF3zEqgvK6JF9dnsuTrTPx9PHngkmH84IKhhPj79NZpqG6myV0pJ2aM4balydiM4T8PXYhnJyNVPtlXwG9WpgJwxyvJvHb3NGwG/mdlKiMHBvLLBaPw9vTgJ/POY3NmGZeNjiLsNL8olHPQ5K6UE9uXV82BwhoAVuzKY9Gk2A779+ZW8fBbu5g4OITFMxJ45O1d3PvaDuJD/SmsbuAfN0/C25rrJSE84KQhjsp5aXJXyom9tyMXHy8PEsL8efqzdK4aPwgfL3uyLqxq4O7l2wgL8GXJrUlEBPrS2NLKL97bC8D3pw1msjV+XbkeHS2jlJNqarGxcnc+l46K4rErRnG0vJ63U+yLoOVW1HPzC1uoa2zlpdunEBFo72b53pTB/M/Vo5k0OISfzx/pyPBVD9OWu1JO6qtDJZTXNfHdyTFcPCKCpPgBPLsunfPjQvjB8hTqGlt45Y4pjBjYcTqA22cN4fZZQxwUteot2nJXykl8daiEA4XVbdvv78glvL8PFyRGICL87PIRFNc0svCfG2mxGd764QySEnQSL3elLXelnEB9Uws/WJaCCDxxwwRmDw9n3f5ibpke33ZDdNrQMC4fE8XBwhqW3TmV+DC9OerONLkr5QS2ZVfQ1GojJqQfP/r3TqYOCaWp1caiSR2nBvjnzZMQkU6HRCr3ot0ySjmBjRml+Hh6sPrBC1g0KYbkrHJGRAUyZlBQh3penh6a2BWgLXeleo0xhqzSOoZG9D9lnYbmVh56cyf3XDiUyfHf9JdvSC9lUnwIwf7ePHH9BGYOC2dIeIAuZ6dOSVvuSvWSDRmlzHniK7YfKT9lnZW78lmTWsQ/Ps9oKyuvayKtoJrZw8MB+wyM102O1THq6rQ0uSvVS/bmVQGwem9hp/uNMby8KRuwj4wprGoAYNPhUgBmWsldqa7Q5K5UL8koqgVgbVoRxpiT9idnlbO/oJr7Lh6GzdifPgXYmFFGoK8X42OCezVe5dy6nNxFxFNEdorIKmt7iIhsFZEMEXlLRHyscl9rO8Pan9BDsSvlVNKLa/EQOFpeT3px7Un7X9mUTYi/Nw/OSWT60FDeTsnBZjNszChl+rAwvDy1Laa67mz+tTwE7G+3/WfgKWPMcKACuMsqvwuosMqfsuop5dZsNkNGcS1XjLWvNbo2rajD/rzKY6xJLeTGKYPp5+PJDUlxHCmr590duRwtr2fWsDBHhK2cWJeSu4jEAlcCL1rbAswB3rWqLAOutd4vtLax9s8VvaWv3Fxe5TGONbcya3g4E2KD+fSE5P7q5iMA3DrDvgbpFWOjCfT14ver0gCYnaj97ersdLXl/jTwc8BmbYcBlcaYFms7Fzj+NEUMkANg7a+y6ncgIveISIqIpJSUlHy76JVyEhlWN0xiVH8uHR3F7pxKiqrtN0yrjjXz5rajXD5mIDEh/QDo5+PJNecPorqhhaggX4adZvikUp05Y3IXkauAYmPM9u78YmPMEmNMkjEmKSIiojs/Wqk+53hyHx7Rn0tHDwTgs/1FNDS38oNl9km+7r1oWIdjvjclDoBZw8J1PLs6a115iGkWcI2ILAD8gCDgGSBERLys1nkskGfVzwPigFwR8QKCgbJuj1wpJ5JeXEN4f18GBPgQ4u/N4FB/PtlXyNeHSth2pJxnb5zIhLiQDseMiwnm0StGctF52vhRZ++MLXdjzGPGmFhjTAJwI/C5Meb7wBfAdVa1xcAK6/1Kaxtr/+ems3FfSrmR9OJaEiPtXSsiwqWjo1ifXsqa1CJ+fdVorp4w6KRjRIR7LxrGqOigk/YpdSbnMrbqF8AjIpKBvU99qVW+FAizyh8BHj23EJXqm2w2Q0Nz60nlZbWNrN5b0LZtjCGjqJbEqG/6zReMi0YE7rt4GHfo3OqqB5zV3DLGmC+BL633mcDUTuo0ANd3Q2xK9Wm/+nAv6/YX89GPZxMV5AfYE/6P/r2TzZllrPrxbMbGBFNU3UhNY0tbyx1gcvwAtv5yLhG6ELXqIfpUhFLfwsHCGt7clkNxTSMPvbmTVpu95/GVTdlszrTfYjq+5F16sX0B62GRHUe8RAb66Y1S1WM0uSv1LTzx6UH6+3jx31eOYktmOX//PJ2M4hr+/MkB5o2K5JoJg/hwZx4Nza2kW9MOJEYGnuFTleo+OuWvUmdp59EKPk0r4r8uPY+7LxhKWkE1z6xL54OdeQT4evGnReM5VFTDyt35rEktJL24lhB/b8L7+zg6dOVGNLkrdZb+uuYgYQE+3DHbfiP0dwvHsiunksySOp6/ZRIRgb6EBfgQO6Afb6fk0NRiIzGyv3bBqF6lyV2ps7Axo5RNh8v49VWj6e9r/+8T4OvF8junsie3ivnW3DEeHsL1k+N46rND+Hl78J2JsY4MW7kh7XNXqhOHS2rJLOk4c2NafjUPv7WLmJB+fH/64A77Ygf4s2BcdIey65JiEYGGZluHkTJK9QZN7kqdwBjDbUuTufSpr/nDx2nUNrawNbOM7/1rM14ewit3TMHXy/OMnxMT0q9t9aT2Y9yV6g3aLaPUCVLzq8mrPMaE2GBeWJ/Fyt35VNQ3EzegH8vvmtY2uVdX3H3BUA4W1jB2kC60oXqXttyVy8oorj1pxaOG5lYW/nMjf11zAJut81kx1qYVIQIv3T6F9+6bSWSgH+Njgnnn3plnldgBLjovguRfzWNAgI6UUb1LW+7KJe3JreSaf2zkmRvPZ+H5MW3lG9JL2Z1TyW5rdMuTN5xPP5+OXSyf7S9i8uABhPX3Jay/Lx/9eDbGGB3topyKttyV07HZTNvi0afyaap9MYwVu/I7lK9JLSTQz4tHrxjJJ6mF3PjCFkpqGtv251UeIzW/mktHR3U4ThO7cjaa3JXTeX3rES74y+dkldadss66A8UAfH2ohMr6JgBaWm18tr+IuSMjufeiYfzrlskcLKzmkbd3tXXfrNtv/6Uw74TkrpSz0eSunM4HO/NobjW8tuVIp/vzK4+xv6Caq8ZH02IzrEktBCA5u5yK+mYuH2NfLOOyMQN5dP5I1qeXsmqPfRbHtWlFDI0I0JWPlNPT5K6cSl7lMXYcrcTP24N3UnI41nTylLufW632h+YmEh/mz0e77Yn709QifL08uGjEN4tf3DojgXExwfxuVRr5lcfYklnGpaO01a6cnyZ35VRWWy3s3y0cS3VDCyt25Z1U5/MDxQwO9Wd4ZH+uHj+ITYdLKalp5NPUQi48LwJ/n2/GEXh6CH/4zlhKahu57aVkmluNdskol6DJXTmVVXsLGBsTxHWTYxk5MJDlm490GO54rKmVjRmlzBkZiYhw1YRobAb+8skB8qsa2rpk2hsfG8Kt0+PJKK4lNMCHSYMH9OYpKdUjNLkrp5FTXs/unEquHDcIEeHWGfGkFVSz42hFW53NmaU0ttiYMzISgBFRgSRG9ued7bl4egjzRkV2+tk/vXwE0cF+LBg3EE8PHRmjnJ8md+U0PraWrrtqvH0Ol2vPjyHQ14vlm7+5sbpufzH+Pp5MGxoK2IcwXjXevj7ptCGhhPh3/jBRkJ83ax+5iN9cPaYnT0GpXqPJXTncf/YWsGxT9knlBwtreHXLEWoamgH4eE8BE2KDiQv1B+yzMX53ciyr9xbwx9X72X6knM8PFHNBYniHuV+uOX8Qnh7fJPlT6e/rhben/pdQrkGfUFUOZYzht6vSKKhqwNNDuGV6PABHyuq4+YUtlNU18ZdPDrBoYgx786r45YKRHY6//+JhZJfV8dKGLJZ8nQnAT+ad16HOkPAAvvzpxWc9dYBSzkyTu+pRj72/h+lDwzpMAdDevrxqCqoaiAz05TcrU0kIC2BUdCCLX0rGZgzP3zKJlbvzWW6Nab9ibMdpdSOD/HjljqlUHWvmy4PF7MurYsH46JO+53hrXyl3ocld9Zi0/GreSM7h4z0FzB4eTlh/35PqrE0rxEPgvftmcveyFO5/fTuDw/wpqGrg3z+YzuT4AcwfG01mSS0FVQ2nTNLB/bxZeH7MKX+JKOVuztjBKCJ+IpIsIrtFJFVE/tcqHyIiW0UkQ0TeEhEfq9zX2s6w9if08DmoPur9Hbl4ewp1Ta08sfZQp3U+TStiSkIocaH+vLg4CW9PD1Lzq3n2polMjv9mSOLQiP7MsuZGV0qdWVfuHjUCc4wxE4DzgfkiMh34M/CUMWY4UAHcZdW/C6iwyp+y6ik309Jq48Nd+cwZGcltM+J5I/koqflVHeocKavjQGFN2yRdcaH+vH3vDF6/e1qn49GVUl13xuRu7I6vN+ZtvQwwB3jXKl8GXGu9X2htY+2fKzqlnttZn15KaW0jiybF8vC88xjg78P/rkzr8MDR2jT7JF2Xjf4mkQ+L6M/MYdpCV+pcdWncl4h4isguoBhYCxwGKo0xLVaVXOB4Z2cMkANg7a8Cwjr5zHtEJEVEUkpKSs7pJFTf896OXEL8vblkRCTB/bz56WUjSM4u58N20wV8mlbEyIGBDA7Tm51Kdbcu3VA1xrQC54tICPABMPL0R3TpM5cASwCSkpI6XxJH9VkNza38ZkUqpbWNNLXaMAZumT6Y+WOjqTrWzKdpRdw4JQ4fL3v74XtT4ng7JYefvbOHVhtcMiKClOxyfjQn0cFnopRrOqsnNowxlcAXwAwgRESO/3KIBY43yfKAOABrfzBQ1h3Bqt6xK6eSq/6+ns2HT33ZNmaU8lZKDkfL66ltbCGnop57X9vB/6xMZcWuPJpabCyaFNtW39NDWH7XVKYNDeWn7+zmvtd3YDNwmU7SpVSPOGPLXUQigGZjTKWI9AMuxX6T9AvgOuBNYDGwwjpkpbW92dr/uTlxIUvVp63Ylce+vGpuWbqVXy0YxR2zEk5aiWh9eil+3h6senA2vl6eNLXYePw/B3hpYxYiMDQigAmxHReFDvLz5uXbp/LY+3t5b0cug4L9GDMoqDdPTSm30ZVumWhgmYh4Ym/pv22MWSUiacCbIvJ7YCew1Kq/FHhVRDKAcuDGHohb9aBt2eWcHxdCRKAvv12Vxr78Kv7y3fF4tXs0/+v0EqYNCWt7zN/Hy4NfXz2aaUNDeez9vdwxa0inS9P5eHnwt+vHM3FwCFFBfrp8nVI95IzJ3RizB5jYSXkmMLWT8gbg+m6JTvW6moZm0vKr+dGcRB6em8hTnx3i759nMGdkZNvcLLkV9WSW1HHz1MEnHX/5mIFcNjrqtElb5JtpBpRSPUNnSVIdbD9Sgc3A1IRQPDyEh+edx6BgP95JyW2rsyG9FIALz4vo9DO0Na6U42lyd2NNLTYKqo51KNuWXY6nhzBxcAhgvxF63eRYvk4vIb/SXnd9eilRQb4kRuo6o0r1VZrc3VRLq43bX05m7hNfUVbb2Fa+LauCsTHBBPh+02N33eQ4jLFPJ9BqM2w8XMoFiRHaQleqD9Pk7qb+sHo/mw6XUd/UypvbcgD72PVdOZVMTei4zNzgMH9mDA3j7ZRc9uRWUlnfzAWJ+hSpUn2ZJnc39E5KDi9vzObOWUO4IDGcVzcfobnVxp7cKppabUxJCD3pmBumxHK0vJ4nrQnAZuskXkr1aTrlrxsoq21kx9FKqo81U1LbyJOfHmLW8DB+uWAkXx4s4e7lKXyaWkR2WR1Ap8l9/phofu2byvr0UsbGBHU6fa9Squ/Q5O4kWm0GATxOs3hzTnk9ft6eRAR2TLwPv7WL9dYIF4DEyP7846ZJeHl6cMnISAaH+vPKpiz6+XhxXlR/BgScvM5oPx9PrpowiDeSj3JBYuejZJRSfYcmdydQXNPA/KfXU1HfRICPF0F+XvzyylEd1gQ91tTKd/5vE/Fh/rx338y28pzyetanl3LX7CHcNiOeID9vgvp542n9kvD0EG6bEc/vP96Pt6dwQ1LcKeP4/rTBvL8jl/k6Ha9SfZ72uTuBv605SE1DM/dfPIwbkuII8PXi1ytS2xaOBnh96xFKaxvZfqSC3TmVbeXvbs9FBO6cPYT4sAAGBPi0Jfbjrk+Kw9/Hk+ZWw9QhJ3fJHDc2Jpj9v53PhLiQ7j5FpVQ30+Tex+3Lq+Kd7bncPjOBn10+kl9fPZq/XT+B8romXrAWhD7W1MrzXx0mKX4A/X29eHljFgA2m+Hd7bnMHh5+2sWhg/t5s2iSfcbmzvrb2ztdt5BSqu/Q5N6HGWP47UdphPr78OO530yNOyEuhCvHR/PC+iyKaxqsVnsTv7hiJNdNjuXjvQUUVzewObOMvMpjXH+arpbjfjF/JK/eNZVBp/kloJRyHprce5jN9u0nxFy9t5Dk7HL+67IRBPl5d9j3s8tG0Nxq48//OcjzXx1m9vBwpiSEcvvMBFpshte2HOHtlByC/Ly6NK1uoJ+33ihVyoVocu9Bz3yWzozH19HQ3HrWx1Yda+aPq/czKjqI7005ueWdEB7AzdMG896OXEprm3hoXmJb+ZwRkby29Sif7Cvk2okx+Hl7nvO5KKWciyb3HrIls4yn1x2iqLqRLw8Wn9Wx1Q3N3PZSMsU1Dfxu4ZiTboAe9+M5iQT4eLa12o+7c/YQyuuaaGyxnXb0i1LKdelQyB5QVd/MI2/tIj7Un5qGFlbtKWD+2OhO69pshvUZpZwX1Z/o4H7UNrZw+0vJpOZV8fwtk0k6zQ3OiEBfVvxoFqEBHce1zxwWxsiBgXh6iC6GoZSb0uTezYwx/PLDvRTXNPLefTN5OyWH93fkcayplX4+J3ePvLb1CL9ekQrA0PAAvDyFwyV1/PPmSczrQl/58MjAk8pEhFfvmtb2XinlfrRbpput3J3Px3sK+Mml57WNajnW3MoXnXTN1Da28Oy6dJLiB/DfV44iITyAphYbf79pIvPHntuDQhGBvic9qaqUch/acu9m/956lGERAdx70TAApg0JI7y/Dx/vKWDBuI5dMy+uz6S0tomli6cwIS6Euy8Y6oiQlVIuSFvu3aiirolt2eVcMTa6w+P9V4yNZt2BIuqbWtrqltQ08sLXmVw5Llqf+FRKdTtN7t3oi4PF2AxcekJf+ZXjo2lotvH5gW+6Zv7xeToNLTZ+evmI3g5TKeUGtFumG61NKyIqyJdxMcEdyqckhBIZ6MuKXfnEDvAnOauM17ce5cYpcQwJD3BQtEopV6bJvZs0NLfy1aESrp0Yc9L8K54ewoJx0byyKZu1aUUAjIoOanvwSCmlutsZk7uIxAHLgSjAAEuMMc+ISCjwFpAAZAM3GGMqxD727hlgAVAP3G6M2dEz4feuqvpmPDzsj+qfaHOmfcm6E7tkjvvBhUPp5+PJmEFBTE0IJTLIr6fDVUq5sa603FuA/zLG7BCRQGC7iKwFbgfWGWMeF5FHgUeBXwBXAInWaxrwnPXT6d25bBsA794746Tx42vTivD38WTG0LBOj40J6ccv5o/s8RiVUgq6cEPVGFNwvOVtjKkB9gMxwEJgmVVtGXCt9X4hsNzYbQFCRKTzxzOdSG1jCzuPVrD9SAVft1vVCOxPma7bX8RF50XoPC5KqT7hrEbLiEgCMBHYCkQZYwqsXYXYu23Anvhz2h2Wa5Wd+Fn3iEiKiKSUlJScbdy9bufRCmwGvD2FZz47hDHfzPa4N6+KourGU3bJKKVUb+tycheR/sB7wMPGmOr2+4w9053V3LbGmCXGmCRjTFJERN+fajYluwIPgUcuHcGOo5VszChr2/fejlw8PYRLRkQ6MEKllPpGl5K7iHhjT+yvG2Pet4qLjne3WD+PD+LOA9pPRRhrlTm17UcqGDEwiDtnJxAd7Mcz6w5hsxl+tyqN5ZuPsGhiTKcLSyullCOcMblbo1+WAvuNMU+227USWGy9XwysaFd+m9hNB6radd84pZZWGzuPVjAlYQC+Xp7cd/EwtmVXcN3zm1i6IYvbZybw+HfHOzpMpZRq05WW+yzgVmCOiOyyXguAx4FLRSQdmGdtA6wGMoEM4AXg/u4Pu3cdKKyhrqmVyfEDALghKY6oIF92HK3kv68cxW+uHn3KOdeVUsoRzjgU0hizAThV5prbSX0DPHCOcfUpKdnlAG1zq/t5e/LibVOobWxhxrDOhz4qpZQj6ROqXZBypILoYD9i2i0ePS42+DRHKKWUY+nEYWdgjCElu+K0KyIppVRfo8n9DPIqj1FY3UCS1d+ulFLOQJP7GWw/UgHQdjNVKaWcgfa5n8BmMzz2/l6abTYuTIzgq0Ml9Pf1YuTAk9cqVUqpvkqT+wk+2JnHWyk5BPh48v4O+7NXFySG4+Wpf+QopZyHJvd2ahtb+PMnB5gQF8J7984graCaTYfLmKnDHZVSTkaTezv/90UGxTWNPH/rZLw8PRgfG8L42BBHh6WUUmdN+xosR8vqeXF9FosmxjBpsN48VUo5N03ulj+sTsPLU/i5LqihlHIBmtyBzYfLWJNaxP0XD2NgsC5/p5Ryfm6f3G02wx9WpzEo2I+7Lxjq6HCUUqpbuH1y/3BXHvvyqvnZ/BG6RJ5SymW4dXJvaG7lr2sOMj42mIUTTloJUCmlnJZbJ/elG7IoqGrgVwtG4aHzsSulXIjbJveq+mae+/Iwl42OYtpQfUhJKeVa3Da5f7grj9rGFh6cm+joUJRSqtu5ZXI3xvBG8lHGxQQzNkYX3VBKuR63TO67cio5UFjDjVPjHB2KUkr1CLdM7m8m59DP25NrJgxydChKKdUj3C651za28NGefK6eEE2gn7ejw1FKqR7hdsl95a586ptauXHqYEeHopRSPeaMyV1EXhKRYhHZ164sVETWiki69XOAVS4i8qyIZIjIHhGZ1JPBfxtvbjvKyIGBTIwLcXQoSinVY7rScn8FmH9C2aPAOmNMIrDO2ga4Aki0XvcAz3VPmN0jo7iWPblVfG9KHCL60JJSynWdMbkbY74Gyk8oXggss94vA65tV77c2G0BQkQkuptiPWdbMssAmDMy0sGRKKVUz/q2fe5RxpgC630hEGW9jwFy2tXLtcpOIiL3iEiKiKSUlJR8yzDOTnJWOVFBvgwO9e+V71NKKUc55xuqxhgDmG9x3BJjTJIxJikiIuJcw+jK95GcVc7UIWHaJaOUcnnfNrkXHe9usX4WW+V5QPsng2KtMoc7Wl5PYXUDU4eEOjoUpZTqcd82ua8EFlvvFwMr2pXfZo2amQ5Uteu+caitWfbbBtM0uSul3IDXmSqIyBvAxUC4iOQCvwEeB94WkbuAI8ANVvXVwAIgA6gH7uiBmL+V5KxyQgN8SIzs7+hQlFKqx50xuRtjbjrFrrmd1DXAA+caVE9IzipnSsIA7W9XSrkFt3hCtaDqGEfL65k6ROdtV0q5B7dI7sna366UcjNukdy3ZpXT39eLUdFBjg5FKaV6hVsk9+SscpISBuCp66QqpdyEyyf30tpGMoprdXy7UsqtuHxyX5NaCMDs4eEOjkQppXqPSyd3Ywz/3mqf4necrpWqlHIjLp3c9+RWkZpfzfenx+v4dqWUW3Hp5P7vrUfx9/Hk2vN1rVSllHtx2eRe3dDMyt35XDNhkK6VqpRyOy6b3D/cmcex5lZunqZrpSql3I9LJvfjN1LHxQQzPjbE0eEopVSvc8nk/sHOPA4U1mirXSnlts44K6QzMcbw7LoMnvrsEEnxA7j2/E5X+FNKKZfnMsm9obmVn7+7h5W781k0KYY/LRqHr5eno8NSSimHcJnkvuTrTFbuzudnl4/g/ouH6bh2pZRbc4nkXtfYwksbs5g3KpIHLhnu6HCUUsrhXOKG6hvJR6msb+a+izWxK6UUuEByb2xp5cX1WUwfGsrk+AGODkcppfoEp0/uH+zIo7C6QbtjlFKqHadO7i2tNp776jDjY4N1Sl+llGrHqZP76n2FHCmr19ExSil1gh5J7iIyX0QOikiGiDzaE98BEODjyWWjo7hs9MCe+gqllHJK3T4UUkQ8gX8ClwK5wDYRWWmMSevu75o7Koq5o6K6+2OVUsrp9UTLfSqQYYzJNMY0AW8CC3vge5RSSp1CTyT3GCCn3XauVdaBiNwjIikiklJSUtIDYSillPty2A1VY8wSY0ySMSYpIiLCUWEopZRL6onkngfEtduOtcqUUkr1kp5I7tuARBEZIiI+wI3Ayh74HqWUUqfQ7aNljDEtIvIjYA3gCbxkjEnt7u9RSil1aj0yK6QxZjWwuic+Wyml1Jk59ROqSimlOifGGEfHgIiUAEe+5eHhQGk3huMs3PG83fGcwT3P2x3PGc7+vOONMZ0ON+wTyf1ciEiKMSbJ0XH0Nnc8b3c8Z3DP83bHc4buPW/tllFKKRekyV0ppVyQKyT3JY4OwEHc8bzd8ZzBPc/bHc8ZuvG8nb7PXSml1MlcoeWulFLqBJrclVLKBTl1cu+tFZ8cSUTiROQLEUkTkVQRecgqDxWRtSKSbv0c4OhYu5uIeIrIThFZZW0PEZGt1vV+y5q7yKWISIiIvCsiB0Rkv4jMcJNr/RPr3/c+EXlDRPxc7XqLyEsiUiwi+9qVdXptxe5Z69z3iMiks/0+p03u7VZ8ugIYDdwkIqMdG1WPaAH+yxgzGpgOPGCd56PAOmNMIrDO2nY1DwH7223/GXjKGDMcqADuckhUPesZ4BNjzEhgAvbzd+lrLSIxwINAkjFmLPY5qW7E9a73K8D8E8pOdW2vABKt1z3Ac2f7ZU6b3HGTFZ+MMQXGmB3W+xrs/9ljsJ/rMqvaMuBahwTYQ0QkFrgSeNHaFmAO8K5VxRXPORi4EFgKYIxpMsZU4uLX2uIF9BMRL8AfKMDFrrcx5mug/ITiU13bhcByY7cFCBGR6LP5PmdO7l1a8cmViEgCMBHYCkQZYwqsXYWAqy0m+zTwc8BmbYcBlcaYFmvbFa/3EKAEeNnqjnpRRAJw8WttjMkD/gYcxZ7Uq4DtuP71hlNf23POb86c3N2KiPQH3gMeNsZUt99n7ONZXWZMq4hcBRQbY7Y7OpZe5gVMAp4zxkwE6jihC8bVrjWA1c+8EPsvt0FAACd3X7i87r62zpzc3WbFJxHxxp7YXzfGvG8VFx3/M836Weyo+HrALOAaEcnG3t02B3tfdIj1Zzu45vXOBXKNMVut7XexJ3tXvtYA84AsY0yJMaYZeB/7vwFXv95w6mt7zvnNmZO7W6z4ZPU1LwX2G2OebLdrJbDYer8YWNHbsfUUY8xjxphYY0wC9uv6uTHm+8AXwHVWNZc6ZwBjTCGQIyIjrKK5QBoufK0tR4HpIuJv/Xs/ft4ufb0tp7q2K4HbrFEz04Gqdt03XWOMcdoXsAA4BBwGfuXoeHroHGdj/1NtD7DLei3A3ge9DkgHPgNCHR1rD53/xcAq6/1QIBnIAN4BfB0dXw+c7/lAinW9PwQGuMO1Bv4XOADsA14FfF3tegNvYL+n0Iz9r7S7TnVtAcE+GvAwsBf7SKKz+j6dfkAppVyQM3fLKKWUOgVN7kop5YI0uSullAvS5K6UUi5Ik7tSSrkgTe5KKeWCNLkrpZQL+n+HyTi27H9LKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "FIM_data = np.load('./chkpt_2/FIM_plot.npy')\n",
    "plt.plot(FIM_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJhnjtlrVMsQ",
    "outputId": "ac0a4507-7aad-4fd5-804b-14c2ddb336d7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using clean\n",
      "Epoch [1/220], Step [100/391] Loss: 1.6038 LR: 0.0500\n",
      "Epoch [1/220], Step [200/391] Loss: 1.3190 LR: 0.0500\n",
      "Epoch [1/220], Step [300/391] Loss: 1.0020 LR: 0.0500\n",
      "Accuracy of the network : 59 %\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy of the network : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_temp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m %\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m accuracy_plot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(accuracy_plot, accuracy_temp)\n\u001b[0;32m---> 83\u001b[0m F_diag \u001b[38;5;241m=\u001b[39m \u001b[43mnngeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m               \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m               \u001b[49m\u001b[43mrepresentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPMatKFAC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(F_diag\u001b[38;5;241m.\u001b[39mtrace())\n\u001b[1;32m     90\u001b[0m FIM_plot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(FIM_plot, F_diag\u001b[38;5;241m.\u001b[39mtrace()\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.conda/envs/sp/lib/python3.9/site-packages/nngeometry/metrics.py:169\u001b[0m, in \u001b[0;36mFIM\u001b[0;34m(model, loader, representation, n_output, variant, device, function, layer_collection)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[1;32m    165\u001b[0m generator \u001b[38;5;241m=\u001b[39m Jacobian(layer_collection\u001b[38;5;241m=\u001b[39mlayer_collection,\n\u001b[1;32m    166\u001b[0m                      model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    167\u001b[0m                      function\u001b[38;5;241m=\u001b[39mfunction_fim,\n\u001b[1;32m    168\u001b[0m                      n_output\u001b[38;5;241m=\u001b[39mn_output)\n\u001b[0;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrepresentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sp/lib/python3.9/site-packages/nngeometry/object/pspace.py:436\u001b[0m, in \u001b[0;36mPMatKFAC.__init__\u001b[0;34m(self, generator, data, examples)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator \u001b[38;5;241m=\u001b[39m generator\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_kfac_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/.conda/envs/sp/lib/python3.9/site-packages/nngeometry/generator/jacobian/__init__.py:249\u001b[0m, in \u001b[0;36mJacobian.get_kfac_blocks\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_output):\n\u001b[1;32m    248\u001b[0m         retain_graph \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mi_output \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_output \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 249\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mi_output\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m                            \u001b[49m\u001b[43monly_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_id \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_collection\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocks[layer_id][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdiv_(n_examples \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_output\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.5\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/sp/lib/python3.9/site-packages/torch/autograd/__init__.py:275\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs)\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/sp/lib/python3.9/site-packages/nngeometry/generator/jacobian/__init__.py:629\u001b[0m, in \u001b[0;36mJacobian._add_hooks.<locals>._hook_x.<locals>.<lambda>\u001b[0;34m(g_o)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_hook_x\u001b[39m(mod, i, o):\n\u001b[1;32m    628\u001b[0m     hook_x(mod, i)\n\u001b[0;32m--> 629\u001b[0m     o\u001b[38;5;241m.\u001b[39mregister_hook(\u001b[38;5;28;01mlambda\u001b[39;00m g_o: \u001b[43mhook_gy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_o\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/sp/lib/python3.9/site-packages/nngeometry/generator/jacobian/__init__.py:693\u001b[0m, in \u001b[0;36mJacobian._hook_compute_kfac_blocks\u001b[0;34m(self, mod, gy)\u001b[0m\n\u001b[1;32m    690\u001b[0m         FactoryMap[layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m]\u001b[38;5;241m.\u001b[39mkfac_xx(block[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    691\u001b[0m             mod, layer, x, gy)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = num_epochs_blur + num_epochs_clean\n",
    "total_step = len(train_loader_clean)\n",
    "curr_lr = learning_rate\n",
    "loss_plot = []\n",
    "accuracy_plot = []\n",
    "FIM_plot = []\n",
    "epoch_chkpt = 0\n",
    "\n",
    "if(load_from_chkpt):\n",
    "  # Load model from checkpoint\n",
    "  path_chkpt = \"./chkpt_2/model.pt\"\n",
    "  loss_plot_chkpt = \"./chkpt_2/loss_plot.npy\"\n",
    "  acc_plot_chkpt = \"./chkpt_2/acc_plot.npy\"\n",
    "  FIM_plot_chkpt = \"./chkpt_2/FIM_plot.npy\"\n",
    "  model = net\n",
    "#   optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "  checkpoint = torch.load(path_chkpt)\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  epoch_chkpt = checkpoint['epoch']\n",
    "  loss = checkpoint['loss']\n",
    "  curr_lr = checkpoint['curr_lr']\n",
    "  loss_plot = np.append(loss_plot, np.load(loss_plot_chkpt))\n",
    "  accuracy_plot = np.append(accuracy_plot, np.load(acc_plot_chkpt))\n",
    "  FIM_plot = np.append(FIM_plot, np.load(FIM_plot_chkpt))\n",
    "\n",
    "  model.train()\n",
    "  print(\"!!!Loaded from checkpoint!!! Epoch:{} Loss:{} curr_lr:{}\".format(epoch_chkpt, loss, curr_lr))\n",
    "\n",
    "for epoch in range(epoch_chkpt, num_epochs):  # loop over the dataset multiple times\n",
    "  if epoch < num_epochs_blur:\n",
    "    train_loader = train_loader_blur\n",
    "    print(\"Using blur\")\n",
    "  else:\n",
    "    train_loader = train_loader_clean\n",
    "    print(\"Using clean\")\n",
    "\n",
    "  # running_loss = 0.0\n",
    "  for i, (inputs, labels) in enumerate(train_loader):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # forward + backward + optimize\n",
    "      outputs = net(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "\n",
    "\n",
    "      optimizer.step()\n",
    "      loss_plot = np.append(loss_plot, loss.item())\n",
    "\n",
    "      if (i+1) % 100 == 0:\n",
    "        print (\"Epoch [{}/{}], Step [{}/{}] Loss: {:.4f} LR: {:.4f}\"\n",
    "                .format(epoch+1, num_epochs, i+1, total_step, loss.item(), curr_lr))\n",
    "\n",
    "  # Decay learning rate\n",
    "  curr_lr = 0.97 * curr_lr\n",
    "  update_lr(optimizer, curr_lr)\n",
    "\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          images, labels = data\n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          # calculate outputs by running images through the network\n",
    "          outputs = net(images)\n",
    "          # the class with the highest energy is what we choose as prediction\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  accuracy_temp = 100 * correct // total\n",
    "  print(f'Accuracy of the network : {accuracy_temp} %')\n",
    "  accuracy_plot = np.append(accuracy_plot, accuracy_temp)\n",
    "\n",
    "  F_diag = nngeometry.metrics.FIM(model=net,\n",
    "                 loader=train_loader,\n",
    "                 representation=PMatKFAC,\n",
    "                 n_output=10,\n",
    "                 device=device)\n",
    "  print(F_diag.trace())\n",
    "\n",
    "  FIM_plot = np.append(FIM_plot, F_diag.trace().item())\n",
    "\n",
    "  if (epoch+1)==2 or (epoch+1)%10==0:\n",
    "    # Save model checkpoint\n",
    "    epoch_chkpt = epoch+1\n",
    "    path_chkpt = \"./chkpt_2/model.pt\"\n",
    "    loss_plot_chkpt = './chkpt_2/loss_plot.npy'\n",
    "    acc_plot_chkpt = './chkpt_2/acc_plot.npy'\n",
    "    FIM_plot_chkpt = './chkpt_2/FIM_plot.npy'\n",
    "    loss_chkpt = loss.item()\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': epoch_chkpt,\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss_chkpt,\n",
    "                'curr_lr': curr_lr,\n",
    "                }, path_chkpt)\n",
    "    np.save(loss_plot_chkpt, loss_plot)\n",
    "    np.save(acc_plot_chkpt, accuracy_plot)\n",
    "    np.save(FIM_plot_chkpt, FIM_plot)\n",
    "    print('!!!Checkpoint saved!!!')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "6h9JVHX45WKh",
    "outputId": "e8a8acce-58e4-4723-ad2a-97b0e5e617f4"
   },
   "outputs": [],
   "source": [
    "plt.plot(accuracy_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "gKz9k59mgawM",
    "outputId": "676a2fa5-311f-43cf-8668-2490e981ad9e"
   },
   "outputs": [],
   "source": [
    "plt.plot(loss_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FIM_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzZXAApB-cHL"
   },
   "outputs": [],
   "source": [
    "PATH = './cifar_net_2.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./acc_2.npy', accuracy_plot)\n",
    "np.save('./loss_2.npy', loss_plot)\n",
    "np.save('./FIM_plot_2.npy', FIM_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = np.load('./acc_2.npy')\n",
    "plt.plot(acc_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_data = np.load('./loss_2.npy')\n",
    "plt.plot(loss_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIM_data = np.load('./FIM_plot_2.npy')\n",
    "plt.plot(FIM_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.gradient(FIM_data)\n",
    "plt.plot(grad)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkKiaV67-yAI",
    "outputId": "c9e114a8-8d70-42f5-a4d7-584d7338aeb2"
   },
   "outputs": [],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_data = np.load('./acc.npy')\n",
    "acc_deficits = [86, 83, 82, 79, 77, 75, 74, 73, 73]\n",
    "deficits = [0, 20, 40, 60, 80, 100, 120, 140, 160]\n",
    "plt.plot(acc_data,'--g')\n",
    "plt.plot(deficits, acc_deficits, 'o-b')\n",
    "plt.ylim(65, 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/tfjgeorge/nngeometry.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class BasicBlock(nn.Module):\n",
    "#     expansion = 1\n",
    "\n",
    "#     def __init__(self, in_planes, planes, stride=1):\n",
    "#         super(BasicBlock, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "#         self.shortcut = nn.Sequential()\n",
    "#         if stride != 1 or in_planes != self.expansion*planes:\n",
    "#             self.shortcut = nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = F.relu(self.conv1(x))\n",
    "#         out = self.conv2(out)\n",
    "#         out = F.relu(out + self.shortcut(x))\n",
    "#         return out\n",
    "\n",
    "# class ResNet(nn.Module):\n",
    "#     def __init__(self, block, num_blocks, num_classes=10):\n",
    "#         super(ResNet, self).__init__()\n",
    "#         self.in_planes = 64\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "#         self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "#         self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "#         self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "#         self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "#         self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "#     def _make_layer(self, block, planes, num_blocks, stride):\n",
    "#         strides = [stride] + [1]*(num_blocks-1)\n",
    "#         layers = []\n",
    "#         for stride in strides:\n",
    "#             layers.append(block(self.in_planes, planes, stride))\n",
    "#             self.in_planes = planes * block.expansion\n",
    "#         return nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         out = self.conv1(x)\n",
    "#         out = F.relu(out)\n",
    "#         out = self.layer1(out)\n",
    "#         out = self.layer2(out)\n",
    "#         out = self.layer3(out)\n",
    "#         out = self.layer4(out)\n",
    "#         out = F.avg_pool2d(out, 4)\n",
    "#         out = out.view(out.size(0), -1)\n",
    "#         out = self.linear(out)\n",
    "#         return out\n",
    "\n",
    "\n",
    "# def ResNet18():\n",
    "#     return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "# model = ResNet18().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "# import torchvision.transforms as transforms\n",
    "# from torchvision.datasets import CIFAR10\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "# ])\n",
    "\n",
    "# testset = Subset(CIFAR10(root='./data/', train=False, download=True,\n",
    "#                          transform=transform), range(100))\n",
    "\n",
    "# def to_tensordataset(dataset):\n",
    "#     d = next(iter(DataLoader(dataset,\n",
    "#                   batch_size=len(dataset))))\n",
    "#     return TensorDataset(d[0].to('cuda'), d[1].to('cuda'))\n",
    "\n",
    "# testloader = DataLoader(to_tensordataset(testset), batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nngeometry.generator import Jacobian\n",
    "# from nngeometry.object import FMatDense\n",
    "# import time\n",
    "\n",
    "# generator = Jacobian(model=model, n_output=10)\n",
    "\n",
    "# start_time = time.time()\n",
    "# K = FMatDense(generator, examples=testloader)\n",
    "# end_time = time.time()\n",
    "\n",
    "# print(f'time: {end_time - start_time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_torch = K.get_dense_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_torch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR-10 All-CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2d4be4ffe46e422abda47318c8e6ebc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42169e65d8b348e1b7571bd857d35121": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73044d7fc152463488f32f6c0cf4e687",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_791e02267eb84006a020029d40d3f037",
      "value": 170498071
     }
    },
    "5a57cf595789487991d2160c2c756e16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb92c28c2ebe4b63ab23b1aa36fe0ff3",
      "placeholder": "​",
      "style": "IPY_MODEL_2d4be4ffe46e422abda47318c8e6ebc0",
      "value": ""
     }
    },
    "73044d7fc152463488f32f6c0cf4e687": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "791e02267eb84006a020029d40d3f037": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7d8c521b1e93440fa382f3205688df4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f858fcc0d16f459087577041d8af7a81",
      "placeholder": "​",
      "style": "IPY_MODEL_fcb12b772f9840b4b783ab83d65fc476",
      "value": " 170499072/? [00:06&lt;00:00, 32933844.61it/s]"
     }
    },
    "91e0cb15346342ef803ab724927a5045": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ebe265266f174d1cbee860e8ba4681d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a57cf595789487991d2160c2c756e16",
       "IPY_MODEL_42169e65d8b348e1b7571bd857d35121",
       "IPY_MODEL_7d8c521b1e93440fa382f3205688df4c"
      ],
      "layout": "IPY_MODEL_91e0cb15346342ef803ab724927a5045"
     }
    },
    "f858fcc0d16f459087577041d8af7a81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb92c28c2ebe4b63ab23b1aa36fe0ff3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcb12b772f9840b4b783ab83d65fc476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
